<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS180: Light Field Camera Project</title>

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Styles -->
    <style>
        body {
            background-color: #1c1c1c;
            color: #f7f7f7;
            padding: 20px;
        }

        .header {
            text-align: center;
            position: relative;
            display: flex;
            justify-content: center;
            align-items: center;
            color: white;
            margin-bottom: 30px;
        }

        h2 {
            text-align: center;
            color: #ffffff;
            margin-bottom: 30px;
        }

        .bg-dark-section {
            background-color: #222;
            padding: 30px;
            border-radius: 8px;
            margin-bottom: 30px;
        }

        .figure-caption {
            color: #d0d0d0;
        }

        .code-block {
            background-color: #2d2d2d;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
            font-family: monospace;
            white-space: pre-wrap;
        }

        .container {
            padding-top: 20px;
            padding-bottom: 40px;
        }

        .implementation-details {
            background-color: #2a2a2a;
            padding: 20px;
            border-radius: 5px;
            margin: 10px 0;
        }
    </style>
</head>

<body>
    <div class="container">
        <!-- Header Section -->
        <div class="header">
            <div>
                <h1>Light Field Camera Project</h1>
                <p class="lead">Implementing Depth Refocusing and Aperture Adjustment</p>
            </div>
        </div>

        <!-- Project Overview -->
        <div class="bg-dark-section">
            <h2>Project Overview</h2>
            <p>
                This project implements key light field camera capabilities using multiple images taken from different
                viewpoints.
                Based on Ng et al.'s work, we demonstrate how simple operations like shifting and averaging can achieve
                complex
                photographic effects such as post-capture refocusing and aperture adjustment.
            </p>
        </div>

        <!-- Part 1: Depth Refocusing -->
        <div class="bg-dark-section">
            <h2>Part 1: Depth Refocusing</h2>
            <p>
                The depth refocusing implementation leverages the principle that distant objects show minimal position
                changes
                across different viewpoints, while nearby objects exhibit significant shifts. By applying appropriate
                shifts
                before averaging, we can focus on objects at different depths.
            </p>

            <div class="implementation-details">
                <h3>Implementation Approach</h3>
                <ul>
                    <li>Center point fixed at (8,8) in the image grid</li>
                    <li>Shift calculation based on distance from center and depth factor</li>
                    <li>C values range from 0 to 3 with 7 evenly spaced steps (0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0)</li>
                </ul>
            </div>

            <div class="container">
                <figure class="figure mb-4">
                    <img src="images/depth_frames.png" class="figure-img img-fluid rounded" alt="Depth frames">
                    <figcaption class="figure-caption">Depth refocusing results at different C values</figcaption>
                </figure>

                <figure class="figure mb-4">
                    <img src="images/focus_sequence.gif" class="figure-img img-fluid rounded" alt="Focus sequence"
                        loop="infinite">
                    <figcaption class="figure-caption">Animated sequence showing focus transition across depths
                    </figcaption>
                </figure>
            </div>
        </div>

        <!-- Part 2: Aperture Adjustment -->
        <div class="bg-dark-section">
            <h2>Part 2: Aperture Adjustment</h2>
            <p>
                The aperture adjustment simulates different lens apertures by controlling how many viewpoints
                contribute
                to the final image. Larger apertures use more viewpoints, creating stronger depth-of-field effects.
            </p>

            <div class="implementation-details">
                <h3>Implementation Approach</h3>
                <ul>
                    <li>Aperture values range from 1.0 to 8.0 with 5 steps</li>
                    <li>Images selected based on distance from center (8,8)</li>
                    <li>Smaller apertures use fewer images, creating sharper overall images</li>
                    <li>Larger apertures incorporate more peripheral views, enhancing depth effects</li>
                </ul>
            </div>

            <div class="container">
                <figure class="figure mb-4">
                    <img src="images/aperature_frames.png" class="figure-img img-fluid rounded"
                        style="max-width: 100%; height: auto; object-fit: cover;" alt="Aperture frames">
                    <figcaption class="figure-caption">Aperture adjustment results with different aperture sizes
                    </figcaption>
                </figure>

                <figure class="figure mb-4">
                    <img src="images/aperture_sequence.gif" class="figure-img img-fluid rounded"
                        style="max-width: 100%; height: auto;" loop="infinite" alt="Aperture sequence">
                    <figcaption class="figure-caption">Animated sequence showing aperture size transition
                    </figcaption>
                </figure>
            </div>
        </div>

        <!-- Conclusion -->
        <div class="bg-dark-section">
            <h2>Conclusion</h2>
            This project showed me the potential of light field photography. By capturing more information when
            taking a picture, we can do things like change focus or adjust the depth of field afterwards. I was also surprised that the parallax effect makes it so that objects can appear to move a lot when closer and not a lot when further away. The last thing is that it was amazing how combining the parallax effect with
            simple shifting and averaging operations can create interesting effects.
        </div>
        <!-- Bootstrap JS -->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js"></script>

        <div style="border-top: 1px solid #dee2e6; margin: 20px 0;"></div>
    </div>
    <!-- Header Section -->
    <div class="header">
        <div>
            <h2>Gradient Domain Fusion Project</h2>
            <p class="lead">Implementing Poisson Blending and Mixed Gradients</p>
        </div>
    </div>
    <!-- Gradient Domain Processing Section -->
    <div class="bg-dark-section">
        <h2>Gradient Domain Processing</h2>
        <p>
            Gradient-domain processing enables seamless blending of objects between images by preserving gradient
            information
            while allowing intensity adjustments. This technique creates natural-looking composites by solving a
            series of
            optimization problems that maintain local image structure while eliminating visible seams.
        </p>
    </div>

    <!-- Toy Problem Section -->
    <div class="bg-dark-section">
        <h3>Part 1: Toy Problem</h3>
        <p>
            I implement a gradient reconstruction system that recovers an image from its x and y gradients plus
            a single intensity value.
            The system solves a least squares problem by constructing sparse matrices that represent gradient
            constraints. For each pixel,
            I minimize (v(x+1,y)-v(x,y) - (s(x+1,y)-s(x,y)))² for x-gradients and (v(x,y+1)-v(x,y) -
            (s(x,y+1)-s(x,y)))² for y-gradients,
            plus an anchor constraint v(1,1)=s(1,1) to fix the absolute intensities.
        </p>
        <div class="row mt-4">
            <div class="col-md-6">
                <figure class="figure">
                    <img src="images/toy_original.jpg" class="figure-img img-fluid rounded">
                    <figcaption class="figure-caption">Original image used for gradient extraction</figcaption>
                </figure>
            </div>
            <div class="col-md-6">
                <figure class="figure">
                    <img src="images/toy_reconstructed.jpg" class="figure-img img-fluid rounded">
                    <figcaption class="figure-caption">Image reconstructed from gradients, achieving
                        an image reconstruction with minimal error (0.01 L2 norm)</figcaption>
                </figure>
            </div>
        </div>
    </div>

    <!-- Poisson Blending Section -->
    <div class="bg-dark-section">
        <h3>Part 2: Poisson Blending</h3>
        <p>
            I implement Poisson blending by solving for pixel values that preserve gradients from the source
            image while matching the
            boundary conditions of the target image. The system uses sparse matrices to efficiently solve the
            optimization problem.
            For each pixel i in the source region and its neighbors j, I minimize (v_i - v_j - (s_i - s_j))²
            when j is also in the
            source region, and (v_i - t_j - (s_i - s_j))² when j is in the target region.
        </p>
        <div class="row mt-4">
            <div class="col-md-4">
                <figure class="figure">
                    <img src="images/preview_raw.jpg" class="figure-img img-fluid rounded">
                    <figcaption class="figure-caption">Naive copy-paste showing distinct boundary artifacts
                    </figcaption>
                </figure>
            </div>
            <div class="col-md-4">
                <figure class="figure">
                    <img src="images/poisson_blend_raw.jpg" class="figure-img img-fluid rounded">
                    <figcaption class="figure-caption">Poisson blending result showing seamless integration with
                        the target image</figcaption>
                </figure>
            </div>
            <div class="col-md-4">
                <figure class="figure">
                    <img src="images/chick_poisson_blend_raw.jpg" class="figure-img img-fluid rounded">
                    <figcaption class="figure-caption">Another Poisson blending example with different source
                        and target images</figcaption>
                </figure>
            </div>
        </div>
    </div>

    <!-- Mixed Gradients Section -->
    <div class="bg-dark-section">
        <h3>Bells & Whistles: Mixed Gradients</h3>
        <p>
            I improved the basic Poisson blending by implementing mixed gradients, where instead of always using
            source gradients,
            I select the gradient with larger magnitude between source and target. This preserves strong edges
            from both images,
            leading to better preservation of high-frequency details. For each pixel pair (i,j), I compare |s_i
            - s_j| with
            |t_i - t_j| and use the larger gradient in the optimization.
        </p>
        <div class="row mt-4">
            <div class="col-md-6">
                <figure class="figure">
                    <img src="images/mixed_gradient_raw.jpg" class="figure-img img-fluid rounded">
                    <figcaption class="figure-caption">Mixed gradient result showing enhanced edge preservation
                    </figcaption>
                </figure>
            </div>
            <div class="col-md-6">
                <figure class="figure">
                    <img src="images/chick_mixed_gradient_raw.jpg" class="figure-img img-fluid rounded">
                    <figcaption class="figure-caption">Second mixed gradient example demonstrating consistent
                        edge handling</figcaption>
                </figure>
            </div>
        </div>
    </div>
    </div>
</body>

</html>